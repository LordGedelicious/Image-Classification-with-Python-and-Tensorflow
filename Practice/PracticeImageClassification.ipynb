{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data from local zip file and extract it\n",
    "# The zip file is downloaded in advance from the following link:\n",
    "# https://dicoding-academy-assets.sgp1.cdn.digitaloceanspaces.com/184/messy-vs-clean-room.zip\n",
    "local_zip = 'C:\\\\Users\\\\Gede Prasidha\\\\Documents\\\\Dicoding\\\\Image Classification with Python and Tensorflow\\\\Image-Classification-with-Python-and-Tensorflow\\\\Practice\\\\tmp\\\\messy-vs-clean-room.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('C:\\\\Users\\\\Gede Prasidha\\\\Documents\\\\Dicoding\\\\Image Classification with Python and Tensorflow\\\\Image-Classification-with-Python-and-Tensorflow\\\\Practice\\\\tmp\\\\')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the directory where the data is stored for both the training and validation data\n",
    "base_diretory = 'C:\\\\Users\\\\Gede Prasidha\\\\Documents\\\\Dicoding\\\\Image Classification with Python and Tensorflow\\\\Image-Classification-with-Python-and-Tensorflow\\\\Practice\\\\tmp\\\\images'\n",
    "train_data_directory = os.path.join(base_diretory, 'train')\n",
    "validation_data_directory = os.path.join(base_diretory, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean', 'messy']\n",
      "['clean', 'messy']\n"
     ]
    }
   ],
   "source": [
    "# View contents of the training data and validation data's directory\n",
    "print(os.listdir(train_data_directory))\n",
    "print(os.listdir(validation_data_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator to prep the data for training and validation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator object for augmenting the training and validation data\n",
    "train_datagenerator = ImageDataGenerator(\n",
    "    rescale=1./255, # To rescale the pixel values from 0-255 to 0-1 in floating numbers\n",
    "    rotation_range=20, # To randomly rotate the images, degree range for random rotations\n",
    "    horizontal_flip=True, # To randomly flip the images horizontally (boolean)\n",
    "    shear_range=0.2, # To randomly shear the images (float, degrees), shearing means to stretch the image in the clockwise direction\n",
    "    fill_mode='nearest' # To fill the empty space in the images with the nearest pixel value\n",
    ")\n",
    "\n",
    "validation_datagenerator = ImageDataGenerator(\n",
    "    rescale=1./255 # To rescale the pixel values from 0-255 to 0-1 in floating numbers\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training and validation\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "    train_data_directory,  # Source directory for the training data\n",
    "    target_size=(150, 150), # Target size for the images\n",
    "    batch_size=4, # Batch size for the training data. The number of samples processed before the model is updated\n",
    "    class_mode='binary' # Binary classification, either \"Clean\" or \"Messy\"\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagenerator.flow_from_directory(\n",
    "    validation_data_directory, # Source directory for the validation data\n",
    "    target_size=(150, 150), # Target size for the images\n",
    "    batch_size=4, # Batch size for the validation data. The number of samples processed before the model is updated\n",
    "    class_mode='binary' # Binary classification, either \"Clean\" or \"Messy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
